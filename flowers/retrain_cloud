#!/bin/bash
declare -r CMD=$1
declare -r MODEL_NAME=article_classifier

if [[ $CMD == 'pre2' ]]; then
  declare -r JOB_ID="${MODEL_NAME}_$(date +%Y%m%d_%H%M%S)"
  echo $JOB_ID > data/job_id_cloud
else
  declare -r JOB_ID=$(cat data/job_id_cloud)
fi

declare -r PROJECT=$(gcloud config list project --format "value(core.project)")
declare -r BUCKET="gs://${PROJECT}-ml"
declare -r GCS_PATH="${BUCKET}/${MODEL_NAME}/jobs/${JOB_ID}"
declare -r DATA_PATH="${BUCKET}/${MODEL_NAME}/data"
declare -r DICT_FILE="${DATA_PATH}/article_dict.txt"

echo
echo "Using job id: " $JOB_ID

if [[ $CMD == 'pre' ]]; then
  echo $DATA_PATH
  echo "${GCS_PATH}/preproc/train"
  python -E preprocess.py \
    --input_dict "$DICT_FILE" \
    --input_path "${DATA_PATH}/train_set*.csv" \
    --output_path "${GCS_PATH}/preproc/train" \
    --empty_emb_path "${DATA_PATH}/empty.emb" \
    --emb_path "${DATA_PATH}/image_embeddings" \
    --setup_file ./setup.py \
    --cloud
exit 0

  echo "${GCS_PATH}/preproc/eval"
  python -E preprocess.py \
    --input_dict "$DICT_FILE" \
    --input_path "${DATA_PATH}/eval_set*.csv" \
    --output_path "${GCS_PATH}/preproc/eval" \
    --empty_emb_path "${DATA_PATH}/empty.emb" \
    --emb_path "${DATA_PATH}/image_embeddings" \
    --setup_file ./setup.py \
    --cloud
#    --autoscaling_algorithm=NONE \
#    --num_workers 1 \
#    --max_num_workers 1 \
# 	 --staging_location "${GCS_PATH}/staging" \
#    --extra_package ./dist/trainer-0.1.tar.gz \

elif [[ $CMD == 'up' ]]; then
  echo $DATA_PATH
  gsutil -m rm "${DATA_PATH}/eval_set*.csv"
  gsutil -m rm "${DATA_PATH}/train_set*.csv"
  gsutil -m cp data/eval_set*.csv $DATA_PATH
  gsutil -m cp data/train_set*.csv $DATA_PATH
elif [[ $CMD == 'train' ]] || [[ $CMD == 'train_test' ]]; then
  if [[ $CMD == 'train' ]]; then
    TRAIN_PATHS="${GCS_PATH}/preproc/train*,${GCS_PATH}/preproc/eval*"
  else
    TRAIN_PATHS="${GCS_PATH}/preproc/train*"
  fi
  LABEL_COUNT=`wc -l < data/article_dict.txt`

  echo "Training on local is quick after preprocessing."
  echo "Labels count: $LABEL_COUNT"
  echo "train paths: $TRAIN_PATHS"

  echo $GCS_PATH
#  rm -rf "${GCS_PATH}/training"

  gcloud ml-engine jobs submit training "${JOB_ID}_$(date +%m%d_%H%M%S)" \
    --stream-logs \
    --module-name trainer.task \
    --package-path trainer \
    --staging-bucket "$BUCKET" \
    --region us-central1 \
    --runtime-version=1.4 \
    -- \
    --label_count $LABEL_COUNT \
    --max_steps 5000 \
    --output_path "${GCS_PATH}/training" \
    --eval_data_paths "${GCS_PATH}/preproc/eval*" \
    --train_data_paths "${TRAIN_PATHS}" \
    --dropout 0.6
else

	python -m apache_beam.examples.wordcount \
		--project $PROJECT \
		--job_name $PROJECT-wordcount \
		--runner DataflowRunner \
		--staging_location $BUCKET/staging \
		--temp_location $BUCKET/temp \
		--output $BUCKET/output

fi
